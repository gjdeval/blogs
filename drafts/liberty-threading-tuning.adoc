---
layout: post
title: Threading (and why you probably don’t need to tune Open Liberty)
categories: blog
author_picture: https://avatars3.githubusercontent.com/u/25179127
seo-title: Threading (and why you probably don’t need to tune Open Liberty) - OpenLiberty.io. 
seo-description: All the application code running on Liberty runs in a single thread pool, so it must be REALLY important to tune it. Right? Nope, not really. The defaults are actually very good. More importantly, the defaults are very good for a wide range of workload types.
blog_description: "All the application code running on Liberty runs in a single thread pool, so it must be REALLY important to tune it. Right? Nope, not really. The defaults are actually very good. More importantly, the defaults are very good for a wide range of workload types."
---
= Threading (and why you probably don’t need to tune Open Liberty)
Gary DeVal <https://github.com/gjdeval>

All the application code running on Liberty runs in a single thread pool called the _default executor_ so it must be REALLY important to tune it. Right?

Nope, not really. The default settings provide a good starting point for the Liberty pool size and the auto-tuning algorithm adjusts from that starting point. This default Liberty threadpool behavior works well for a wide range of workload types

There are other threads running in Liberty which are not in the default executor pool; e.g. utility threads like OSGi framework threads, JVM garbage collections threads, Java NIO selector threads, etc. ​The default executor pool is the set of threads where your application code runs and this post describes that pool.

== Threading settings

There are just a few threading configuration settings available for the Liberty default executor pool.

* `name` This is the name of the thread pool, and it’s also part of the name of the threads that live in this pool. The default pool name is Default Executor. The only effect of changing the name is to make it more difficult for you to find the default executor threads in a thread dump. So don't change it.
* `coreThreads` This is the minimum number of threads in the pool. Liberty creates a new thread for each piece of offered work, until there are `coreThreads` threads in the pool. If `coreThreads` is not configured, at runtime we set `coreThreads` to a multiple of the number of CPUs (hardware threads) on your system; currently, that multiple is `2`.
* `maxThreads` This is the maximum number of threads in the pool. The default value is `-1`, which translates to `MAX_INT` or, effectively, unlimited.

Liberty uses an auto-tuning algorithm to find the sweet spot for how many threads the server needs. The algorithm continually adjusts the number of threads in the pool within the defined bounds for `coreThreads` and `maxThreads`. 


== How the auto-tuning algorithm works 

Liberty's threadpool controller runs a loop every 1500 ms, and on each cycle sets the Liberty default executor pool size to a value between `coreThreads` and `maxThreads`. The controller maintains a set of data about the threadpool performance, recording the throughput (tasks completed by the threadpool per controller cycle) at the various pool sizes which have been previously tried. The historical throughput data is then compared to the current cycle's throughput to decide what the pool size should be going forward. At each cycle the pool size might be increased or decreased incrementally, or left unchanged.

The number of threads by which the pool size might be changed in a controller cycle is one-half of the `coreThreads` value or the number of CPUs, whichever is smaller. For example, by default if Liberty is running on a platform that has 12 CPUs, `coreThreads` is `24` and the controller adjusts the pool size in 12-thread increments. But, on the same 12-CPU platform, if `coreThreads` is set to `4`, the controller adjusts the pool size by two threads at a time. So the `coreThreads` setting not only determines the minimum number of threads in the pool, but also affects how dynamically the pool size is changed as the threadpool controller runs.

At each cycle, the controller records the current throughput with the historical data for the current pool size, and then compares the current throughput to the historical throughput for both smaller and larger pool sizes. If the data shows that throughput was significantly higher at smaller or larger pool size, the pool is adjusted in the higher-throughput direction; if neither higher nor lower pool sizes show better throughput, the pool size is left unchanged.

There are a variety of factors, besides the default executor pool size, that might have transient effects on throughput in the Liberty server, such as variations in workload offered, garbage collection pauses, and perturbations in adjacent systems (e.g. database response variability). Due to these factors the  relationship between pool size and observed throughput tends to not be perfectly smooth or continuous. Therefore, to improve the "signal quality" derived from the historical throughput data, the controller considers not just the closest larger/smaller pool size performance, but several increments in each direction.

For example, if the current pool size is 24 and the increment/decrement is two threads, the controller looks at data for 22, 20, 18, and 16 threads to calculate a _shrink score_ (the probability that shrinking the pool is likely to improve performance), and looks at data for 26, 28, 30, and 32 threads to calculate a _grow score_. This broader range of input to the shrink/grow calculations results in better decisions about pool size in environments where the transaction flow might tend to be lumpy or transaction latency is long or highly variable, as can be common in cloud service scenarios.

What if there is no historical data to guide the decision? For example, maybe the pool has been growing and is at the largest size tried so far so there is no data about throughput for larger pool sizes. In that case, the controller "flips a coin" to decide whether moving in the no-data direction is a good idea. This is analagous to how a human threadpool tuner would try various threadpool sizes to see how they perform before settling on an optimal value for the configuration and workload.

In addition to the basic larger/smaller pool throughput evaluation, there are a few heuristics or "rules of thumb" applied by the threadpool controller:

* If the pool size has been unchanged for several cycles in a row, the controller arbitrarily grows or shrinks the pool by one increment, chosing the direction with a coin flip. This behavior helps the controller avoid getting stuck in a size which may be a local optimum (so the basic throughput comparison would lead to no change) but is suboptimal across a broader range of pool sizes.
* If the CPU utilization reported by the JVM for the CPUs available to the Liberty process exceeds a high-CPU threshold, the controller becomes reluctant to add more threads. This applies the general computing performance principle that adding threads to a system that is already running at high CPU utilization is unlikely to increase throughput.
* If the default executor throughput falls below a low-throughput threshold, calculated as "tasks-completed per thread", and there are no tasks waiting in the threadpool queue,  the controller becomes reluctant to add more threads, and more inclined to shrink the pool. This provides a sort of ballast to the controller operation, tending toward reasonably small pool sizes as long as they are sufficient to do the work at hand.
* If the pool size is already pretty small (within a few increments of the `coreThreads` value), the controller does not bother shrinking the pool further toward `coreThreads`, even if other factors might lean toward shrinking. This has the benefit of reducing random grow/shrink churn in the pool, for which there is some cost and no likely benefit.
* Workload offered to the server is likely to change over time, which can render historical throughput data irrelevant to the current operating conditions. To keep the controller focused on how things are going now, historical data might be pruned if it is very different from current throughput or if the data is from an old/unreliable observation. 

== Fighting deadlocks 

If no tasks were completed in the prior controller cycle, and there are tasks waiting in the threadpool queue, the controller declares a deadlock and invokes _hang resolution_ logic. Hang resolution adds threads to the pool in the hope that more threads will enable the server to resume normal execution. Hang resolution also shortens the controller cycle duration in an effort to break out of the deadlock quickly.

When the controller observes that tasks are being completed again, normal operation resumes: the controller cycle returns to its normal duration, and pool size is adjusted based on the usual throughput criteria.

The controller notes the pool size at which the hang was resolved and treats this as a new floor on the pool size. This is so that, after a hang, the pool does not shrink below the _hang resolution pool size_. This avoids the unhappy possibility of the pool cycling in and out of the hang condition; i.e. shrinking the pool based on normal throughput calculations to a size where the hang reoccurs, then resolving the hang, then shrinking the pool, and so on. There is also a mechanism to gradually reduce the hang resolution floor over time so that the system is not permanently stuck at an unnecessarily high pool size by a transitory hang condition.

== When to tune the Liberty threadpool

For many environments, configurations, and workloads, the autonomic tuning provided by the Liberty threadpool works well with no configuration or tuning by the operator. But there are some situations in which setting `coreThreads` and/or `maxThreads` might be desirable, or even necessary. Here are a couple of examples.

=== When to tune maxThreads

Some OS or container environments might impose a hard cap on the number of threads that a process can spin up. Liberty currently has no way to know whether such a cap applies, or what the value is. So if Liberty is going to run in such a thread-limited environment, the operator should configure `maxThreads` to an appropriate value, considering the system thread limit and the thread usage of the Liberty server. As discussed before, `maxThreads` does not apply to the total thread count in Liberty; it applies just to the default executor pool size (there are also other threads running in Liberty, such as JVM utility threads--JIT and GC--and a few administrative Liberty threads). The system operator can calculate a good `maxThreads` value by subtracting the number of other (non-default executor) Liberty threads from the system thread cap, and probably subtracting a few more as a safety margin. The number of other Liberty threads can be determined by starting the Liberty server in the thread-limited environment with `maxThreads` set to a very small value like `4`, and then taking a thread dump on the Liberty JVM or using some OS utility to report the number of threads running in the Liberty process.

=== When to tune coreThreads

The operator might plan to run many Liberty instances in a shared OS or container environment, or to run a Liberty instance in a shared environment with other processes. Recall that Liberty chooses a default value for `coreThreads` of twice the number of CPUs available. Liberty does not know about other processes (Liberty instances or otherwise) that are running in the same OS, and so it cannot adjust the default `coreThreads` value to account for other processes with which it will be sharing the available CPUs. The default `coreThreads` value might cause Liberty to spin up more threads than optimal, considering the other processes competing for CPU resources. In this situation, it might be beneficial to set `coreThreads` to a value that reflects the proportion of the CPU resources that the operator would like Liberty to make use of. For example, if you have a 24-CPU box on which you want to run 12 instances of Liberty, you could set `coreThreads=4` so that the aggregated `coreThreads` for all the Liberty instances is twice the number of CPUs on the box.

== In conclusion ...

What should you take away from this? Don’t assume you need to tune the Liberty default executor settings. We try really, really hard to make the defaults work for as many types of workloads as possible. Yes, there will be some edge cases where you may need to adjust `coreThreads` and `maxThreads`, but at least try the defaults first.

_Adapted and updated from an original article by https://github.com/garypicher[Gary Picher]._